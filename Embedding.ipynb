{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输入格式\n",
    "\n",
    "\"\"\"\n",
    "input : {\"creative_id\":\"1,2,3,4,5\",\n",
    "        \"ad_id\":\"1,2,3,4,5\",\n",
    "        \"advertiser_id\":\"1,2,3,4,5\",\n",
    "        \"product_id\":\"1,2,3,4,5\",\n",
    "        \"product_category\":\"1,2,3,4,5\",\n",
    "        \"industry\":\"1,2,3,4,5\"}\n",
    "        \n",
    "label1 : age  sigmoid\n",
    "label2 : gender softmax\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预训练embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据\n",
    "df_ad,df_click_log,df_user,df_click_log_test = loadData(\"./train/\",mode=\"pro\")\n",
    "\n",
    "# 整合宽表\n",
    "df_total_train = df_click_log.merge(df_user, how='left', on=\"user_id\")\n",
    "df_total_train = df_total_train.merge(df_ad, how='left', on=\"creative_id\")\n",
    "df_total_train = df_total_train.fillna(\"UNK\").replace([\"\\\\N\"],\"UNK\")\n",
    "df_total_train.head(5)\n",
    "\n",
    "df_total_test = df_click_log_test.merge(df_ad, how='left', on=\"creative_id\")\n",
    "df_total_test = df_total_test.fillna(\"UNK\").replace([\"\\\\N\"],\"UNK\")\n",
    "df_total_test.head(5)\n",
    "\n",
    "# 设定参数\n",
    "features = [\"creative_id\",\"ad_id\",\"product_id\",\"product_category\",\"advertiser_id\",\"industry\"]\n",
    "SEQ_LEN = 45\n",
    "negsample = 0\n",
    "feature_max_idx = {}\n",
    "\n",
    "dict_table = {}\n",
    "max_num = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "table = pickle.load(open(\"./\"+method+\"/data.table\",'rb'))\n",
    "\n",
    "for key in features:\n",
    "    print(\"Starting to process \" + key)\n",
    "    df_total_train[key] = transform(df_total_train[key],table[key])\n",
    "    df_total_test[key] = transform(df_total_test[key],table[key])\n",
    "    \n",
    "#pickle.dump(dict_table,open(base_path+\"data.table\",'wb'))\n",
    "\n",
    "data_train = df_total_train.sort_values(\"time\")\n",
    "data_test = df_total_test.sort_values(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多线程生成序列\n",
    "\n",
    "def fun_avg1(uId,groupData,val):\n",
    "    return groupData[val].agg(lambda x : list(x))\n",
    "\n",
    "def applyParallel(dfGrouped, func1,val):\n",
    "    ret = Parallel(n_jobs=8)(delayed(func1)(name,group,val) for name, group in dfGrouped)\n",
    "    return ret\n",
    "\n",
    "\n",
    "# 多进程生成序列\n",
    "\n",
    "def combine (pairs,key) : \n",
    "    \n",
    "    return pairs[1][key].agg(lambda x : list(x))\n",
    "\n",
    "combineAdd = partial(combine,key=\"creative_id\")\n",
    "\n",
    "def multiProcess (maxProcess = 5):\n",
    "    res = []\n",
    "    pool = Pool(maxProcess)\n",
    "    res = pool.map(combineAdd,data.groupby(\"user_id\",as_index=False))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return res\n",
    "\n",
    "\n",
    "#dataTrain = pd.read_csv(\"dataTrainStr.csv\")\n",
    "#dataTest = pd.read_csv(\"dataTestStr.csv\")\n",
    "\n",
    "pool = Pool(5)\n",
    "\n",
    "df = {}\n",
    "\n",
    "for item in features:\n",
    "    \n",
    "    print(item)\n",
    "    \n",
    "    combineAdd = partial(combine,key=item)\n",
    "    \n",
    "    df[item] = pool.map(combineAdd,dataTest.groupby(\"user_id\",as_index=False))\n",
    "    \n",
    "pickle.dump(df,open(\"test_seq.table\",\"wb\"))\n",
    "\n",
    "del df\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils.utils import loadData,encode,transform,getSeq,getUserAvgSeq,getUserAvgSeq,upload\n",
    "from model.W2V import wvmodel\n",
    "from model.LGB import base_predict,base_train\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.utils import encode,transform\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from functools import partial\n",
    "\n",
    "method = \"test_nn_seq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成序列\n",
    "features = {\"creative_id\":128,\"ad_id\":128,\"product_id\":32,\"product_category\":4,\"advertiser_id\":32,\"industry\":4}\n",
    "\n",
    "#seq_train = pickle.load(open(\"train_seq.table\",\"rb\"))    ## no str\n",
    "\n",
    "#seq_test = pickle.load(open(\"test_seq.table\",\"rb\"))      ## no str\n",
    "\n",
    "#seq = {}\n",
    "\n",
    "#for item in features :\n",
    "    \n",
    "    #seq[item] = seq_train[item] +  seq_test[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train creative_id\n",
      "**********Word2Vector*********\n",
      "**********initing*********\n",
      "**********training*********\n",
      "**********saving*********\n",
      "Starting to train ad_id\n",
      "**********Word2Vector*********\n",
      "**********initing*********\n"
     ]
    }
   ],
   "source": [
    "for item,size in features.items() :\n",
    "\n",
    "    print(\"Starting to train \" + item)\n",
    "\n",
    "    params = {\"min_count\":1,  # 保留的最小出现频次\n",
    "          \"alpha\":0.1,       # 初始学习率\n",
    "          \"seed\":2020,\n",
    "          \"min_alpha\":0.01,   # 随着学习进行，学习率线性下降到这个最小数\n",
    "          \"window\" : 5,   # 当前和预测单词之间的最大距离\n",
    "          \"size\":size,     # 生成词向量的维度\n",
    "          \"compute_loss\":False,# 损失(loss)值，如果是True 就会保存\n",
    "          \"workers\":8}   # 几个CPU进行跑\n",
    "\n",
    "    model = wvmodel(seq[item],10,\"./test_nn_seq/\" + item + \".w2v\",params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36_Tensorflow",
   "language": "python",
   "name": "python36_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
